{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2477b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/asus/yolo/env/lib/python3.12/site-packages (11.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3521527a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462407c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fb132a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb211aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import threading\n",
    "from pathlib import Path\n",
    "\n",
    "class ImageCropper:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Bulk Image Cropper\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "        # Variables\n",
    "        self.selected_images = []\n",
    "        self.current_image_index = 0\n",
    "        self.current_image = None\n",
    "        self.display_image = None\n",
    "        self.crop_coords = None\n",
    "        self.is_cropping = False\n",
    "        self.start_x = self.start_y = 0\n",
    "        self.rect_id = None\n",
    "        self.scale_factor = 1.0\n",
    "        \n",
    "        # Load face cascade\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "        \n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Left panel - Controls\n",
    "        left_frame = ttk.Frame(main_frame)\n",
    "        left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))\n",
    "        \n",
    "        # File selection\n",
    "        file_frame = ttk.LabelFrame(left_frame, text=\"Image Selection\", padding=10)\n",
    "        file_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(file_frame, text=\"Select Images\", command=self.select_images).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(file_frame, text=\"Select Folder\", command=self.select_folder).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.image_count_label = ttk.Label(file_frame, text=\"No images selected\")\n",
    "        self.image_count_label.pack(pady=5)\n",
    "        \n",
    "        # Manual cropping controls\n",
    "        manual_frame = ttk.LabelFrame(left_frame, text=\"Manual Cropping\", padding=10)\n",
    "        manual_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(manual_frame, text=\"Previous Image\", command=self.prev_image).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Next Image\", command=self.next_image).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Crop Current\", command=self.crop_current_manual).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Reset Crop\", command=self.reset_crop).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        # Manual crop info\n",
    "        ttk.Label(manual_frame, text=\"Manual crops preserve exact\", font=('TkDefaultFont', 8)).pack(pady=(5,0))\n",
    "        ttk.Label(manual_frame, text=\"bounding box dimensions\", font=('TkDefaultFont', 8)).pack()\n",
    "        \n",
    "        self.current_image_label = ttk.Label(manual_frame, text=\"No image loaded\")\n",
    "        self.current_image_label.pack(pady=5)\n",
    "        \n",
    "        # Automatic cropping controls\n",
    "        auto_frame = ttk.LabelFrame(left_frame, text=\"Automatic Cropping\", padding=10)\n",
    "        auto_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        self.crop_mode = tk.StringVar(value=\"face\")\n",
    "        ttk.Radiobutton(auto_frame, text=\"Face Detection\", variable=self.crop_mode, value=\"face\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(auto_frame, text=\"Body Detection\", variable=self.crop_mode, value=\"body\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(auto_frame, text=\"Center Crop\", variable=self.crop_mode, value=\"center\").pack(anchor=tk.W)\n",
    "        \n",
    "        # Crop size settings\n",
    "        size_frame = ttk.Frame(auto_frame)\n",
    "        size_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(size_frame, text=\"Width:\").grid(row=0, column=0, sticky=tk.W)\n",
    "        self.width_var = tk.StringVar(value=\"700\")\n",
    "        ttk.Entry(size_frame, textvariable=self.width_var, width=8).grid(row=0, column=1, padx=5)\n",
    "        \n",
    "        ttk.Label(size_frame, text=\"Height:\").grid(row=1, column=0, sticky=tk.W)\n",
    "        self.height_var = tk.StringVar(value=\"700\")\n",
    "        ttk.Entry(size_frame, textvariable=self.height_var, width=8).grid(row=1, column=1, padx=5)\n",
    "        \n",
    "        ttk.Button(auto_frame, text=\"Auto Crop All\", command=self.auto_crop_all).pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        # Auto crop info\n",
    "        ttk.Label(auto_frame, text=\"Auto crops resize to specified\", font=('TkDefaultFont', 8)).pack(pady=(5,0))\n",
    "        ttk.Label(auto_frame, text=\"width/height dimensions\", font=('TkDefaultFont', 8)).pack()\n",
    "        \n",
    "        # Output settings\n",
    "        output_frame = ttk.LabelFrame(left_frame, text=\"Output Settings\", padding=10)\n",
    "        output_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(output_frame, text=\"Select Output Folder\", command=self.select_output_folder).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.output_folder = tk.StringVar(value=\"./cropped_images\")\n",
    "        ttk.Label(output_frame, text=\"Output:\").pack(anchor=tk.W)\n",
    "        ttk.Label(output_frame, textvariable=self.output_folder, wraplength=200).pack(anchor=tk.W)\n",
    "        \n",
    "        # Progress bar\n",
    "        self.progress = ttk.Progressbar(left_frame, mode='determinate')\n",
    "        self.progress.pack(fill=tk.X, pady=10)\n",
    "        \n",
    "        # Right panel - Image display\n",
    "        right_frame = ttk.Frame(main_frame)\n",
    "        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Canvas for image display\n",
    "        self.canvas = tk.Canvas(right_frame, bg='white', cursor='cross')\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Bind mouse events for manual cropping\n",
    "        self.canvas.bind(\"<Button-1>\", self.start_crop)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_crop)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.end_crop)\n",
    "        \n",
    "        # Status bar\n",
    "        self.status_label = ttk.Label(self.root, text=\"Ready\", relief=tk.SUNKEN)\n",
    "        self.status_label.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        \n",
    "    def select_images(self):\n",
    "        try:\n",
    "            files = filedialog.askopenfilenames(\n",
    "                title=\"Select Images\",\n",
    "                filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff *.gif\")]\n",
    "            )\n",
    "            if files:  # Only proceed if files were actually selected\n",
    "                self.selected_images = list(files)\n",
    "                self.update_image_count()\n",
    "                self.current_image_index = 0\n",
    "                self.load_current_image()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting images: {str(e)}\")\n",
    "            \n",
    "    def select_folder(self):\n",
    "        try:\n",
    "            folder = filedialog.askdirectory(title=\"Select Image Folder\")\n",
    "            if folder:\n",
    "                image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
    "                self.selected_images = []\n",
    "                for file_path in Path(folder).rglob('*'):\n",
    "                    if file_path.suffix.lower() in image_extensions:\n",
    "                        self.selected_images.append(str(file_path))\n",
    "                self.update_image_count()\n",
    "                if self.selected_images:\n",
    "                    self.current_image_index = 0\n",
    "                    self.load_current_image()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting folder: {str(e)}\")\n",
    "                \n",
    "    def select_output_folder(self):\n",
    "        try:\n",
    "            folder = filedialog.askdirectory(title=\"Select Output Folder\")\n",
    "            if folder:\n",
    "                self.output_folder.set(folder)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting output folder: {str(e)}\")\n",
    "            \n",
    "    def update_image_count(self):\n",
    "        count = len(self.selected_images)\n",
    "        self.image_count_label.config(text=f\"{count} images selected\")\n",
    "        \n",
    "    def load_current_image(self):\n",
    "        if not self.selected_images:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            image_path = self.selected_images[self.current_image_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #load with pil first to get DPI\n",
    "            pil_img = Image.open(image_path)\n",
    "            self.current_image = cv2.imread(image_path)\n",
    "            \n",
    "            if self.current_image is None:\n",
    "                messagebox.showerror(\"Error\", f\"Could not load image: {image_path}\")\n",
    "                return\n",
    "                \n",
    "            # Update current image label\n",
    "            filename = os.path.basename(image_path)\n",
    "            self.current_image_label.config(text=f\"{self.current_image_index + 1}/{len(self.selected_images)}: {filename}\")\n",
    "            \n",
    "            # Display image\n",
    "            self.display_image_on_canvas()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading image: {str(e)}\")\n",
    "        \n",
    "    def display_image_on_canvas(self):\n",
    "        if self.current_image is None:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Check if root window still exists\n",
    "            if not self.root.winfo_exists():\n",
    "                return\n",
    "                \n",
    "            # Convert BGR to RGB\n",
    "            rgb_image = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Calculate scale factor to fit canvas\n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            if canvas_width <= 1 or canvas_height <= 1:\n",
    "                self.root.after(100, self.display_image_on_canvas)\n",
    "                return\n",
    "                \n",
    "            img_height, img_width = rgb_image.shape[:2]\n",
    "            \n",
    "            scale_x = canvas_width / img_width\n",
    "            scale_y = canvas_height / img_height\n",
    "            self.scale_factor = min(scale_x, scale_y, 1.0)\n",
    "            \n",
    "            new_width = int(img_width * self.scale_factor)\n",
    "            new_height = int(img_height * self.scale_factor)\n",
    "            \n",
    "            # Resize image\n",
    "            resized_image = cv2.resize(rgb_image, (new_width, new_height))\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            pil_image = Image.fromarray(resized_image)\n",
    "            \n",
    "            # Create PhotoImage with explicit master reference\n",
    "            self.display_image = ImageTk.PhotoImage(pil_image, master=self.root)\n",
    "            \n",
    "            # Clear canvas and display image\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_image(canvas_width//2, canvas_height//2, image=self.display_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying image: {str(e)}\")\n",
    "            # Try to show error message if root still exists\n",
    "            try:\n",
    "                if self.root.winfo_exists():\n",
    "                    messagebox.showerror(\"Error\", f\"Error displaying image: {str(e)}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    def start_crop(self, event):\n",
    "        self.is_cropping = True\n",
    "        self.start_x = event.x\n",
    "        self.start_y = event.y\n",
    "        if self.rect_id:\n",
    "            self.canvas.delete(self.rect_id)\n",
    "            \n",
    "    def draw_crop(self, event):\n",
    "        if self.is_cropping:\n",
    "            if self.rect_id:\n",
    "                self.canvas.delete(self.rect_id)\n",
    "            self.rect_id = self.canvas.create_rectangle(\n",
    "                self.start_x, self.start_y, event.x, event.y,\n",
    "                outline='red', width=2\n",
    "            )\n",
    "            \n",
    "    def end_crop(self, event):\n",
    "        if self.is_cropping:\n",
    "            self.is_cropping = False\n",
    "            \n",
    "            # Calculate crop coordinates in original image\n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            # Get image position on canvas\n",
    "            img_height, img_width = self.current_image.shape[:2]\n",
    "            scaled_width = int(img_width * self.scale_factor)\n",
    "            scaled_height = int(img_height * self.scale_factor)\n",
    "            \n",
    "            img_x = (canvas_width - scaled_width) // 2\n",
    "            img_y = (canvas_height - scaled_height) // 2\n",
    "            \n",
    "            # Convert canvas coordinates to image coordinates\n",
    "            x1 = max(0, int((self.start_x - img_x) / self.scale_factor))\n",
    "            y1 = max(0, int((self.start_y - img_y) / self.scale_factor))\n",
    "            x2 = min(img_width, int((event.x - img_x) / self.scale_factor))\n",
    "            y2 = min(img_height, int((event.y - img_y) / self.scale_factor))\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                self.crop_coords = (x1, y1, x2, y2)\n",
    "            else:\n",
    "                self.crop_coords = None\n",
    "                if self.rect_id:\n",
    "                    self.canvas.delete(self.rect_id)\n",
    "                    self.rect_id = None\n",
    "                \n",
    "\n",
    "                \n",
    "    def reset_crop(self):\n",
    "        if self.rect_id:\n",
    "            self.canvas.delete(self.rect_id)\n",
    "            self.rect_id = None\n",
    "        self.crop_coords = None\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def crop_current_manual(self):\n",
    "        if self.current_image is not None and self.crop_coords:\n",
    "            try:\n",
    "                # Get the crop coordinates in original image dimensions\n",
    "                x1, y1, x2, y2 = self.crop_coords\n",
    "                \n",
    "                # Ensure coordinates are within image bounds\n",
    "                img_height, img_width = self.current_image.shape[:2]\n",
    "                x1 = max(0, min(x1, img_width - 1))\n",
    "                y1 = max(0, min(y1, img_height - 1))\n",
    "                x2 = max(0, min(x2, img_width))\n",
    "                y2 = max(0, min(y2, img_height))\n",
    "                \n",
    "                # Ensure valid dimensions\n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    cropped = self.current_image[y1:y2, x1:x2]\n",
    "                    self.save_cropped_image_manual(cropped, self.current_image_index)\n",
    "                    messagebox.showinfo(\"Success\", \"Image cropped and saved!\")\n",
    "                else:\n",
    "                    messagebox.showwarning(\"Warning\", \"Invalid crop area selected!\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error cropping image: {str(e)}\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select a crop area first!\")\n",
    "\n",
    "\n",
    "            \n",
    "    def prev_image(self):\n",
    "        if self.selected_images and self.current_image_index > 0:\n",
    "            try:\n",
    "                self.current_image_index -= 1\n",
    "                self.load_current_image()\n",
    "                self.reset_crop()\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error loading previous image: {str(e)}\")\n",
    "            \n",
    "    def next_image(self):\n",
    "        if self.selected_images and self.current_image_index < len(self.selected_images) - 1:\n",
    "            try:\n",
    "                self.current_image_index += 1\n",
    "                self.load_current_image()\n",
    "                self.reset_crop()\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error loading next image: {str(e)}\")\n",
    "            \n",
    "    def auto_crop_all(self):\n",
    "        if not self.selected_images:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select images first!\")\n",
    "            return\n",
    "            \n",
    "        # Create output directory\n",
    "        output_dir = self.output_folder.get()\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Start processing in a separate thread\n",
    "        thread = threading.Thread(target=self.process_images_thread)\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        \n",
    "    def process_images_thread(self):\n",
    "        total_images = len(self.selected_images)\n",
    "        self.progress['maximum'] = total_images\n",
    "        \n",
    "        try:\n",
    "            target_width = int(self.width_var.get())\n",
    "            target_height = int(self.height_var.get())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Please enter valid width and height values!\")\n",
    "            return\n",
    "            \n",
    "        success_count = 0\n",
    "        \n",
    "        for i, image_path in enumerate(self.selected_images):\n",
    "            try:\n",
    "                # Update status\n",
    "                self.root.after(0, lambda: self.status_label.config(text=f\"Processing {i+1}/{total_images}\"))\n",
    "                \n",
    "                # Load image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                    \n",
    "                # Apply auto cropping based on mode\n",
    "                mode = self.crop_mode.get()\n",
    "                cropped_image = self.auto_crop_image(image, mode, target_width, target_height)\n",
    "                \n",
    "                if cropped_image is not None:\n",
    "                    self.save_cropped_image(cropped_image, i)\n",
    "                    success_count += 1\n",
    "                    \n",
    "                # Update progress\n",
    "                self.root.after(0, lambda: self.progress.config(value=i+1))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        # Show completion message\n",
    "        self.root.after(0, lambda: messagebox.showinfo(\"Complete\", f\"Processed {success_count}/{total_images} images successfully!\"))\n",
    "        self.root.after(0, lambda: self.status_label.config(text=\"Ready\"))\n",
    "        self.root.after(0, lambda: self.progress.config(value=0))\n",
    "        \n",
    "    def auto_crop_image(self, image, mode, target_width, target_height):\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        if mode == \"face\":\n",
    "            # Face detection\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            \n",
    "            if len(faces) > 0:\n",
    "                # Get the largest face\n",
    "                largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "                x, y, w, h = largest_face\n",
    "                \n",
    "                # Expand crop area around face\n",
    "                padding = max(w, h) // 2\n",
    "                x1 = max(0, x - padding)\n",
    "                y1 = max(0, y - padding)\n",
    "                x2 = min(width, x + w + padding)\n",
    "                y2 = min(height, y + h + padding)\n",
    "                \n",
    "                cropped = image[y1:y2, x1:x2]\n",
    "                return cv2.resize(cropped, (target_width, target_height))\n",
    "                \n",
    "        elif mode == \"body\":\n",
    "            # Body detection\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            bodies = self.body_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            \n",
    "            if len(bodies) > 0:\n",
    "                # Get the largest body\n",
    "                largest_body = max(bodies, key=lambda x: x[2] * x[3])\n",
    "                x, y, w, h = largest_body\n",
    "                \n",
    "                cropped = image[y:y+h, x:x+w]\n",
    "                return cv2.resize(cropped, (target_width, target_height))\n",
    "                \n",
    "        # Default to center crop\n",
    "        aspect_ratio = target_width / target_height\n",
    "        \n",
    "        if width / height > aspect_ratio:\n",
    "            # Image is wider - crop width\n",
    "            new_width = int(height * aspect_ratio)\n",
    "            x_offset = (width - new_width) // 2\n",
    "            cropped = image[:, x_offset:x_offset + new_width]\n",
    "        else:\n",
    "            # Image is taller - crop height\n",
    "            new_height = int(width / aspect_ratio)\n",
    "            y_offset = (height - new_height) // 2\n",
    "            cropped = image[y_offset:y_offset + new_height, :]\n",
    "            \n",
    "        return cv2.resize(cropped, (target_width, target_height))\n",
    "        \n",
    "    def save_cropped_image_manual(self, cropped_image, index):\n",
    "        \"\"\"Save manually cropped image without resizing - preserves exact crop dimensions\"\"\"\n",
    "        try:\n",
    "            output_dir = self.output_folder.get()\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            original_path = self.selected_images[index]\n",
    "            filename = os.path.basename(original_path)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            \n",
    "            # Add manual crop suffix to distinguish from auto-cropped images\n",
    "            output_path = os.path.join(output_dir, f\"{name}_manual_crop{ext}\")\n",
    "            success = cv2.imwrite(output_path, cropped_image)\n",
    "            \n",
    "            if not success:\n",
    "                raise Exception(f\"Failed to save image to {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving manually cropped image: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    def save_cropped_image(self, cropped_image, index):\n",
    "        \"\"\"Save automatically cropped image with resizing applied\"\"\"\n",
    "        try:\n",
    "            output_dir = self.output_folder.get()\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            original_path = self.selected_images[index]\n",
    "            filename = os.path.basename(original_path)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            \n",
    "            # Add auto crop suffix to distinguish from manually cropped images\n",
    "            output_path = os.path.join(output_dir, f\"{name}_auto_crop{ext}\")\n",
    "            success = cv2.imwrite(output_path, cropped_image)\n",
    "            \n",
    "            if not success:\n",
    "                raise Exception(f\"Failed to save image to {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving cropped image: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        app = ImageCropper(root)\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting application: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361d4463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde87849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df23a632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 1 faces.\n",
      "Detected 2 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 4 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 2 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n",
      "Detected 2 faces.\n",
      "Detected 1 faces.\n",
      "Detected 1 faces.\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from tkinter import colorchooser\n",
    "\n",
    "\n",
    "\n",
    "class ImageCropper:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Bulk Image Cropper\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "        # Variables\n",
    "        self.selected_images = []\n",
    "        self.current_image_index = 0\n",
    "        self.current_image = None\n",
    "        self.display_image = None\n",
    "        self.crop_coords = None\n",
    "        self.is_cropping = False\n",
    "        self.start_x = self.start_y = 0\n",
    "        self.rect_id = None\n",
    "        self.scale_factor = 1.0\n",
    "        \n",
    "        # Load face cascade\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "        \n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Left panel - Controls\n",
    "        left_frame = ttk.Frame(main_frame)\n",
    "        left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))\n",
    "        \n",
    "        # File selection\n",
    "        file_frame = ttk.LabelFrame(left_frame, text=\"Image Selection\", padding=10)\n",
    "        file_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(file_frame, text=\"Select Images\", command=self.select_images).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(file_frame, text=\"Select Folder\", command=self.select_folder).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.image_count_label = ttk.Label(file_frame, text=\"No images selected\")\n",
    "        self.image_count_label.pack(pady=5)\n",
    "        \n",
    "        # Manual cropping controls\n",
    "        manual_frame = ttk.LabelFrame(left_frame, text=\"Manual Cropping\", padding=10)\n",
    "        manual_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(manual_frame, text=\"Previous Image\", command=self.prev_image).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Next Image\", command=self.next_image).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Crop Current\", command=self.crop_current_manual).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Reset Crop\", command=self.reset_crop).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        # Manual crop info\n",
    "        ttk.Label(manual_frame, text=\"Manual crops preserve exact\", font=('TkDefaultFont', 8)).pack(pady=(5,0))\n",
    "        ttk.Label(manual_frame, text=\"bounding box dimensions\", font=('TkDefaultFont', 8)).pack()\n",
    "        \n",
    "        self.current_image_label = ttk.Label(manual_frame, text=\"No image loaded\")\n",
    "        self.current_image_label.pack(pady=5)\n",
    "        \n",
    "        # Automatic cropping controls\n",
    "        auto_frame = ttk.LabelFrame(left_frame, text=\"Automatic Cropping\", padding=10)\n",
    "        auto_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        self.crop_mode = tk.StringVar(value=\"face\")\n",
    "        ttk.Radiobutton(auto_frame, text=\"Face Detection\", variable=self.crop_mode, value=\"face\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(auto_frame, text=\"Body Detection\", variable=self.crop_mode, value=\"body\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(auto_frame, text=\"Center Crop\", variable=self.crop_mode, value=\"center\").pack(anchor=tk.W)\n",
    "        \n",
    "        # Crop size settings\n",
    "        size_frame = ttk.Frame(auto_frame)\n",
    "        size_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(size_frame, text=\"Width:\").grid(row=0, column=0, sticky=tk.W)\n",
    "        self.width_var = tk.StringVar(value=\"700\")\n",
    "        ttk.Entry(size_frame, textvariable=self.width_var, width=8).grid(row=0, column=1, padx=5)\n",
    "        \n",
    "        ttk.Label(size_frame, text=\"Height:\").grid(row=1, column=0, sticky=tk.W)\n",
    "        self.height_var = tk.StringVar(value=\"700\")\n",
    "        ttk.Entry(size_frame, textvariable=self.height_var, width=8).grid(row=1, column=1, padx=5)\n",
    "        \n",
    "        ttk.Button(auto_frame, text=\"Auto Crop All\", command=self.auto_crop_all).pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        # Auto crop info\n",
    "        ttk.Label(auto_frame, text=\"Auto crops resize to specified\", font=('TkDefaultFont', 8)).pack(pady=(5,0))\n",
    "        ttk.Label(auto_frame, text=\"width/height dimensions\", font=('TkDefaultFont', 8)).pack()\n",
    "        \n",
    "        # Output settings\n",
    "        output_frame = ttk.LabelFrame(left_frame, text=\"Output Settings\", padding=10)\n",
    "        output_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "\n",
    "\n",
    "        ttk.Button(output_frame, text=\"Select Background Color\", command=self.select_background_color).pack(fill=tk.X, pady=2)\n",
    "\n",
    "        # ✅ Add this line\n",
    "        self.apply_bg_color = tk.BooleanVar(value=False)\n",
    "\n",
    "        # Background color toggle\n",
    "        ttk.Checkbutton(output_frame, text=\"Apply Background Color\", variable=self.apply_bg_color).pack(anchor=tk.W, pady=2)\n",
    "\n",
    "        # Background color picker\n",
    "        ttk.Button(output_frame, text=\"Select Background Color\", command=self.select_background_color).pack(fill=tk.X, pady=2)\n",
    "\n",
    "        # Color preview\n",
    "        self.bg_color_var = tk.StringVar(value=\"#FFFFFF\")\n",
    "        self.color_preview = tk.Label(output_frame, text=\"      \", background=self.bg_color_var.get(), borderwidth=1, relief=\"solid\")\n",
    "        self.color_preview.pack(anchor=tk.W, pady=2)\n",
    "\n",
    "        # Display hex value\n",
    "        ttk.Label(output_frame, textvariable=self.bg_color_var).pack(anchor=tk.W)\n",
    "\n",
    "\n",
    "        \n",
    "        ttk.Button(output_frame, text=\"Select Output Folder\", command=self.select_output_folder).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.output_folder = tk.StringVar(value=\"./cropped_images\")\n",
    "        ttk.Label(output_frame, text=\"Output:\").pack(anchor=tk.W)\n",
    "        ttk.Label(output_frame, textvariable=self.output_folder, wraplength=200).pack(anchor=tk.W)\n",
    "        \n",
    "        # Progress bar\n",
    "        self.progress = ttk.Progressbar(left_frame, mode='determinate')\n",
    "        self.progress.pack(fill=tk.X, pady=10)\n",
    "        \n",
    "        # Right panel - Image display\n",
    "        right_frame = ttk.Frame(main_frame)\n",
    "        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Canvas for image display\n",
    "        self.canvas = tk.Canvas(right_frame, bg='white', cursor='cross')\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Bind mouse events for manual cropping\n",
    "        self.canvas.bind(\"<Button-1>\", self.start_crop)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_crop)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.end_crop)\n",
    "        \n",
    "        # Status bar\n",
    "        self.status_label = ttk.Label(self.root, text=\"Ready\", relief=tk.SUNKEN)\n",
    "        self.status_label.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "\n",
    "    def select_background_color(self):\n",
    "        color_code = colorchooser.askcolor(title=\"Choose Background Color\")[1]\n",
    "        if color_code:\n",
    "            self.bg_color_var.set(color_code)\n",
    "            self.color_preview.config(background=color_code)\n",
    "\n",
    "    \n",
    "    def hex_to_bgr(self, hex_color):\n",
    "        h = hex_color.lstrip('#')\n",
    "        return tuple(int(h[i:i+2], 16) for i in (4, 2, 0))  # BGR order\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def select_images(self):\n",
    "        try:\n",
    "            files = filedialog.askopenfilenames(\n",
    "                title=\"Select Images\",\n",
    "                filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff *.gif\")]\n",
    "            )\n",
    "            if files:  # Only proceed if files were actually selected\n",
    "                self.selected_images = list(files)\n",
    "                self.update_image_count()\n",
    "                self.current_image_index = 0\n",
    "                self.load_current_image()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting images: {str(e)}\")\n",
    "            \n",
    "    def select_folder(self):\n",
    "        try:\n",
    "            folder = filedialog.askdirectory(title=\"Select Image Folder\")\n",
    "            if folder:\n",
    "                image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
    "                self.selected_images = []\n",
    "                for file_path in Path(folder).rglob('*'):\n",
    "                    if file_path.suffix.lower() in image_extensions:\n",
    "                        self.selected_images.append(str(file_path))\n",
    "                self.update_image_count()\n",
    "                if self.selected_images:\n",
    "                    self.current_image_index = 0\n",
    "                    self.load_current_image()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting folder: {str(e)}\")\n",
    "                \n",
    "    def select_output_folder(self):\n",
    "        try:\n",
    "            folder = filedialog.askdirectory(title=\"Select Output Folder\")\n",
    "            if folder:\n",
    "                self.output_folder.set(folder)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting output folder: {str(e)}\")\n",
    "            \n",
    "    def update_image_count(self):\n",
    "        count = len(self.selected_images)\n",
    "        self.image_count_label.config(text=f\"{count} images selected\")\n",
    "        \n",
    "    def load_current_image(self):\n",
    "        if not self.selected_images:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            image_path = self.selected_images[self.current_image_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #load with pil first to get DPI\n",
    "            pil_img = Image.open(image_path)\n",
    "            self.current_image = cv2.imread(image_path)\n",
    "            \n",
    "            if self.current_image is None:\n",
    "                messagebox.showerror(\"Error\", f\"Could not load image: {image_path}\")\n",
    "                return\n",
    "                \n",
    "            # Update current image label\n",
    "            filename = os.path.basename(image_path)\n",
    "            self.current_image_label.config(text=f\"{self.current_image_index + 1}/{len(self.selected_images)}: {filename}\")\n",
    "            \n",
    "            # Display image\n",
    "            self.display_image_on_canvas()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading image: {str(e)}\")\n",
    "        \n",
    "    def display_image_on_canvas(self):\n",
    "        if self.current_image is None:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Check if root window still exists\n",
    "            if not self.root.winfo_exists():\n",
    "                return\n",
    "                \n",
    "            # Convert BGR to RGB\n",
    "            rgb_image = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Calculate scale factor to fit canvas\n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            if canvas_width <= 1 or canvas_height <= 1:\n",
    "                self.root.after(100, self.display_image_on_canvas)\n",
    "                return\n",
    "                \n",
    "            img_height, img_width = rgb_image.shape[:2]\n",
    "            \n",
    "            scale_x = canvas_width / img_width\n",
    "            scale_y = canvas_height / img_height\n",
    "            self.scale_factor = min(scale_x, scale_y, 1.0)\n",
    "            \n",
    "            new_width = int(img_width * self.scale_factor)\n",
    "            new_height = int(img_height * self.scale_factor)\n",
    "            \n",
    "            # Resize image\n",
    "            resized_image = cv2.resize(rgb_image, (new_width, new_height))\n",
    "            \n",
    "            # Convert to PIL Image\n",
    "            pil_image = Image.fromarray(resized_image)\n",
    "            \n",
    "            # Create PhotoImage with explicit master reference\n",
    "            self.display_image = ImageTk.PhotoImage(pil_image, master=self.root)\n",
    "            \n",
    "            # Clear canvas and display image\n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_image(canvas_width//2, canvas_height//2, image=self.display_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying image: {str(e)}\")\n",
    "            # Try to show error message if root still exists\n",
    "            try:\n",
    "                if self.root.winfo_exists():\n",
    "                    messagebox.showerror(\"Error\", f\"Error displaying image: {str(e)}\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "    def start_crop(self, event):\n",
    "        self.is_cropping = True\n",
    "        self.start_x = event.x\n",
    "        self.start_y = event.y\n",
    "        if self.rect_id:\n",
    "            self.canvas.delete(self.rect_id)\n",
    "            \n",
    "    def draw_crop(self, event):\n",
    "        if self.is_cropping:\n",
    "            if self.rect_id:\n",
    "                self.canvas.delete(self.rect_id)\n",
    "            self.rect_id = self.canvas.create_rectangle(\n",
    "                self.start_x, self.start_y, event.x, event.y,\n",
    "                outline='red', width=2\n",
    "            )\n",
    "            \n",
    "    def end_crop(self, event):\n",
    "        if self.is_cropping:\n",
    "            self.is_cropping = False\n",
    "            \n",
    "            # Calculate crop coordinates in original image\n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            # Get image position on canvas\n",
    "            img_height, img_width = self.current_image.shape[:2]\n",
    "            scaled_width = int(img_width * self.scale_factor)\n",
    "            scaled_height = int(img_height * self.scale_factor)\n",
    "            \n",
    "            img_x = (canvas_width - scaled_width) // 2\n",
    "            img_y = (canvas_height - scaled_height) // 2\n",
    "            \n",
    "            # Convert canvas coordinates to image coordinates\n",
    "            x1 = max(0, int((self.start_x - img_x) / self.scale_factor))\n",
    "            y1 = max(0, int((self.start_y - img_y) / self.scale_factor))\n",
    "            x2 = min(img_width, int((event.x - img_x) / self.scale_factor))\n",
    "            y2 = min(img_height, int((event.y - img_y) / self.scale_factor))\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                self.crop_coords = (x1, y1, x2, y2)\n",
    "            else:\n",
    "                self.crop_coords = None\n",
    "                if self.rect_id:\n",
    "                    self.canvas.delete(self.rect_id)\n",
    "                    self.rect_id = None\n",
    "                \n",
    "\n",
    "                \n",
    "    def reset_crop(self):\n",
    "        if self.rect_id:\n",
    "            self.canvas.delete(self.rect_id)\n",
    "            self.rect_id = None\n",
    "        self.crop_coords = None\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    def crop_current_manual(self):\n",
    "        if self.current_image is not None and self.crop_coords:\n",
    "            try:\n",
    "                # Get the crop coordinates in original image dimensions\n",
    "                x1, y1, x2, y2 = self.crop_coords\n",
    "                \n",
    "                # Ensure coordinates are within image bounds\n",
    "                img_height, img_width = self.current_image.shape[:2]\n",
    "                x1 = max(0, min(x1, img_width - 1))\n",
    "                y1 = max(0, min(y1, img_height - 1))\n",
    "                x2 = max(0, min(x2, img_width))\n",
    "                y2 = max(0, min(y2, img_height))\n",
    "                \n",
    "                # Ensure valid dimensions\n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    cropped = self.current_image[y1:y2, x1:x2]\n",
    "                    self.save_cropped_image_manual(cropped, self.current_image_index)\n",
    "                    messagebox.showinfo(\"Success\", \"Image cropped and saved!\")\n",
    "                else:\n",
    "                    messagebox.showwarning(\"Warning\", \"Invalid crop area selected!\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error cropping image: {str(e)}\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select a crop area first!\")\n",
    "\n",
    "\n",
    "            \n",
    "    def prev_image(self):\n",
    "        if self.selected_images and self.current_image_index > 0:\n",
    "            try:\n",
    "                self.current_image_index -= 1\n",
    "                self.load_current_image()\n",
    "                self.reset_crop()\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error loading previous image: {str(e)}\")\n",
    "            \n",
    "    def next_image(self):\n",
    "        if self.selected_images and self.current_image_index < len(self.selected_images) - 1:\n",
    "            try:\n",
    "                self.current_image_index += 1\n",
    "                self.load_current_image()\n",
    "                self.reset_crop()\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error loading next image: {str(e)}\")\n",
    "            \n",
    "    def auto_crop_all(self):\n",
    "        if not self.selected_images:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select images first!\")\n",
    "            return\n",
    "            \n",
    "        # Create output directory\n",
    "        output_dir = self.output_folder.get()\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Start processing in a separate thread\n",
    "        thread = threading.Thread(target=self.process_images_thread)\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "        \n",
    "    def process_images_thread(self):\n",
    "        total_images = len(self.selected_images)\n",
    "        self.progress['maximum'] = total_images\n",
    "        \n",
    "        try:\n",
    "            target_width = int(self.width_var.get())\n",
    "            target_height = int(self.height_var.get())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Please enter valid width and height values!\")\n",
    "            return\n",
    "            \n",
    "        success_count = 0\n",
    "        \n",
    "        for i, image_path in enumerate(self.selected_images):\n",
    "            try:\n",
    "                # Update status\n",
    "                self.root.after(0, lambda: self.status_label.config(text=f\"Processing {i+1}/{total_images}\"))\n",
    "                \n",
    "                # Load image\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is None:\n",
    "                    continue\n",
    "                    \n",
    "                # Apply auto cropping based on mode\n",
    "                mode = self.crop_mode.get()\n",
    "                cropped_image = self.auto_crop_image(image, mode, target_width, target_height)\n",
    "                \n",
    "                if cropped_image is not None:\n",
    "                    self.save_cropped_image(cropped_image, i)\n",
    "                    success_count += 1\n",
    "                    \n",
    "                # Update progress\n",
    "                self.root.after(0, lambda: self.progress.config(value=i+1))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "                continue\n",
    "                \n",
    "        # Show completion message\n",
    "        self.root.after(0, lambda: messagebox.showinfo(\"Complete\", f\"Processed {success_count}/{total_images} images successfully!\"))\n",
    "        self.root.after(0, lambda: self.status_label.config(text=\"Ready\"))\n",
    "        self.root.after(0, lambda: self.progress.config(value=0))\n",
    "        \n",
    "    def auto_crop_image(self, image, mode, target_width, target_height):\n",
    "        height, width = image.shape[:2]\n",
    "        \n",
    "        if mode == \"face\":\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            print(f\"Detected {len(faces)} faces.\")\n",
    "\n",
    "\n",
    "            if len(faces) > 0:\n",
    "                largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "                x, y, w, h = largest_face\n",
    "\n",
    "                padding = max(w, h) // 2\n",
    "                x1 = max(0, x - padding)\n",
    "                y1 = max(0, y - padding)\n",
    "                x2 = min(width, x + w + padding)\n",
    "                y2 = min(height, y + h + padding)\n",
    "\n",
    "                if self.apply_bg_color.get():\n",
    "                    # Apply GrabCut to image\n",
    "                    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "                    bgdModel = np.zeros((1, 65), np.float64)\n",
    "                    fgdModel = np.zeros((1, 65), np.float64)\n",
    "                    rect = (x1, y1, x2 - x1, y2 - y1)\n",
    "\n",
    "                    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "                    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "                    person = image * mask2[:, :, np.newaxis]\n",
    "\n",
    "                    bgr_color = self.hex_to_bgr(self.bg_color_var.get())\n",
    "                    background = np.full(image.shape, bgr_color, dtype=np.uint8)\n",
    "\n",
    "                    result = np.where(mask2[:, :, np.newaxis] == 0, background, person)\n",
    "\n",
    "                    cropped = result[y1:y2, x1:x2]\n",
    "\n",
    "                else:\n",
    "                    cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "                # Apply Gaussian blur\n",
    "                cropped = cv2.GaussianBlur(cropped, (3, 3), 0.5)\n",
    "\n",
    "                # Resize to target size\n",
    "                cropped = cv2.resize(cropped, (target_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Apply CLAHE enhancement\n",
    "                lab = cv2.cvtColor(cropped, cv2.COLOR_BGR2LAB)\n",
    "                l, a, b = cv2.split(lab)\n",
    "                clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(8, 8))\n",
    "                cl = clahe.apply(l)\n",
    "                merged_lab = cv2.merge((cl, a, b))\n",
    "                enhanced = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "                return enhanced\n",
    "\n",
    "\n",
    "                \n",
    "        elif mode == \"body\":\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            bodies = self.body_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "            if len(bodies) > 0:\n",
    "                largest_body = max(bodies, key=lambda x: x[2] * x[3])\n",
    "                x, y, w, h = largest_body\n",
    "\n",
    "                padding = max(w, h) // 4\n",
    "                x1 = max(0, x - padding)\n",
    "                y1 = max(0, y - padding)\n",
    "                x2 = min(width, x + w + padding)\n",
    "                y2 = min(height, y + h + padding)\n",
    "\n",
    "                if self.apply_bg_color.get():\n",
    "                    # Apply GrabCut to segment body from background\n",
    "                    mask = np.zeros(image.shape[:2], np.uint8)\n",
    "                    bgdModel = np.zeros((1, 65), np.float64)\n",
    "                    fgdModel = np.zeros((1, 65), np.float64)\n",
    "                    rect = (x1, y1, x2 - x1, y2 - y1)\n",
    "\n",
    "                    cv2.grabCut(image, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "                    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "\n",
    "                    person = image * mask2[:, :, np.newaxis]\n",
    "\n",
    "                    bgr_color = self.hex_to_bgr(self.bg_color_var.get())\n",
    "                    background = np.full(image.shape, bgr_color, dtype=np.uint8)\n",
    "\n",
    "                    result = np.where(mask2[:, :, np.newaxis] == 0, background, person)\n",
    "\n",
    "                    cropped = result[y1:y2, x1:x2]\n",
    "\n",
    "                else:\n",
    "                    cropped = image[y1:y2, x1:x2]\n",
    "\n",
    "                # ✅ Common processing for both paths\n",
    "\n",
    "                # Apply Gaussian blur\n",
    "                cropped = cv2.GaussianBlur(cropped, (3, 3), 0.5)\n",
    "\n",
    "                # Resize to target size\n",
    "                cropped = cv2.resize(cropped, (target_width, target_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "                # Apply CLAHE enhancement\n",
    "                lab = cv2.cvtColor(cropped, cv2.COLOR_BGR2LAB)\n",
    "                l, a, b = cv2.split(lab)\n",
    "                clahe = cv2.createCLAHE(clipLimit=0.5, tileGridSize=(8, 8))\n",
    "                cl = clahe.apply(l)\n",
    "                merged_lab = cv2.merge((cl, a, b))\n",
    "                enhanced = cv2.cvtColor(merged_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "                return enhanced\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "        # Default to center crop\n",
    "        aspect_ratio = target_width / target_height\n",
    "        \n",
    "        if width / height > aspect_ratio:\n",
    "            # Image is wider - crop width\n",
    "            new_width = int(height * aspect_ratio)\n",
    "            x_offset = (width - new_width) // 2\n",
    "            cropped = image[:, x_offset:x_offset + new_width]\n",
    "        else:\n",
    "            # Image is taller - crop height\n",
    "            new_height = int(width / aspect_ratio)\n",
    "            y_offset = (height - new_height) // 2\n",
    "            cropped = image[y_offset:y_offset + new_height, :]\n",
    "            \n",
    "        return cv2.resize(cropped, (target_width, target_height))\n",
    "        \n",
    "    def save_cropped_image_manual(self, cropped_image, index):\n",
    "        \"\"\"Save manually cropped image without resizing - preserves exact crop dimensions\"\"\"\n",
    "        try:\n",
    "            output_dir = self.output_folder.get()\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            original_path = self.selected_images[index]\n",
    "            filename = os.path.basename(original_path)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            \n",
    "            # Add manual crop suffix to distinguish from auto-cropped images\n",
    "            output_path = os.path.join(output_dir, f\"{name}_manual_crop{ext}\")\n",
    "            success = cv2.imwrite(output_path, cropped_image)\n",
    "            \n",
    "            if not success:\n",
    "                raise Exception(f\"Failed to save image to {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving manually cropped image: {str(e)}\")\n",
    "            raise e\n",
    "    \n",
    "    def save_cropped_image(self, cropped_image, index):\n",
    "        \"\"\"Save automatically cropped image with resizing applied\"\"\"\n",
    "        try:\n",
    "            output_dir = self.output_folder.get()\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            original_path = self.selected_images[index]\n",
    "            filename = os.path.basename(original_path)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            \n",
    "            # Add auto crop suffix to distinguish from manually cropped images\n",
    "            output_path = os.path.join(output_dir, f\"{name}_auto_crop{ext}\")\n",
    "            ext = os.path.splitext(output_path)[1].lower()\n",
    "            if ext in ['.jpg', '.jpeg']:\n",
    "                success = cv2.imwrite(output_path, cropped_image, [int(cv2.IMWRITE_JPEG_QUALITY), 100])\n",
    "            else:\n",
    "                success = cv2.imwrite(output_path, cropped_image)\n",
    "\n",
    "            \n",
    "            if not success:\n",
    "                raise Exception(f\"Failed to save image to {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving cropped image: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        app = ImageCropper(root)\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting application: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e7ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c8838e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4c6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a8debb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'https://github.com/danielgatis/rembg/releases/download/v0.0.0/u2net.onnx' to file '/home/asus/snap/code/195/.local/share/.u2net/u2net.onnx'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 face detected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 176M/176M [00:00<00:00, 234GB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n",
      "1 face detected\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, colorchooser\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image, ImageTk\n",
    "import os\n",
    "import threading\n",
    "from pathlib import Path\n",
    "from rembg import remove\n",
    "\n",
    "class ImageCropper:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Bulk Image Cropper\")\n",
    "        self.root.geometry(\"1200x800\")\n",
    "        \n",
    "        # Variables\n",
    "        self.selected_images = []\n",
    "        self.current_image_index = 0\n",
    "        self.current_image = None\n",
    "        self.display_image = None\n",
    "        self.crop_coords = None\n",
    "        self.is_cropping = False\n",
    "        self.start_x = self.start_y = 0\n",
    "        self.rect_id = None\n",
    "        self.scale_factor = 1.0\n",
    "        \n",
    "        # Load face and body cascades\n",
    "        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "        self.body_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_fullbody.xml')\n",
    "        \n",
    "        # Background color toggle\n",
    "        self.apply_bg_color = tk.BooleanVar(value=False)\n",
    "        \n",
    "        # Edge quality control\n",
    "        self.edge_smoothness = tk.DoubleVar(value=10.0)\n",
    "        \n",
    "        # Advanced processing toggle\n",
    "        self.use_advanced_processing = tk.BooleanVar(value=True)\n",
    "        \n",
    "        self.setup_ui()\n",
    "        \n",
    "    def setup_ui(self):\n",
    "        # Main frame\n",
    "        main_frame = ttk.Frame(self.root)\n",
    "        main_frame.pack(fill=tk.BOTH, expand=True, padx=10, pady=10)\n",
    "        \n",
    "        # Left panel - Controls\n",
    "        left_frame = ttk.Frame(main_frame)\n",
    "        left_frame.pack(side=tk.LEFT, fill=tk.Y, padx=(0, 10))\n",
    "        \n",
    "        # File selection\n",
    "        file_frame = ttk.LabelFrame(left_frame, text=\"Image Selection\", padding=10)\n",
    "        file_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(file_frame, text=\"Select Images\", command=self.select_images).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(file_frame, text=\"Select Folder\", command=self.select_folder).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.image_count_label = ttk.Label(file_frame, text=\"No images selected\")\n",
    "        self.image_count_label.pack(pady=5)\n",
    "        \n",
    "        # Manual cropping controls\n",
    "        manual_frame = ttk.LabelFrame(left_frame, text=\"Manual Cropping\", padding=10)\n",
    "        manual_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        ttk.Button(manual_frame, text=\"Previous Image\", command=self.prev_image).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Next Image\", command=self.next_image).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Crop Current\", command=self.crop_current_manual).pack(fill=tk.X, pady=2)\n",
    "        ttk.Button(manual_frame, text=\"Reset Crop\", command=self.reset_crop).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        # Manual crop info\n",
    "        ttk.Label(manual_frame, text=\"Manual crops preserve exact\", font=('TkDefaultFont', 8)).pack(pady=(5,0))\n",
    "        ttk.Label(manual_frame, text=\"bounding box dimensions\", font=('TkDefaultFont', 8)).pack()\n",
    "        \n",
    "        self.current_image_label = ttk.Label(manual_frame, text=\"No image loaded\")\n",
    "        self.current_image_label.pack(pady=5)\n",
    "        \n",
    "        # Automatic cropping controls\n",
    "        auto_frame = ttk.LabelFrame(left_frame, text=\"Automatic Cropping\", padding=10)\n",
    "        auto_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        self.crop_mode = tk.StringVar(value=\"face\")\n",
    "        ttk.Radiobutton(auto_frame, text=\"Face Detection\", variable=self.crop_mode, value=\"face\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(auto_frame, text=\"Body Detection\", variable=self.crop_mode, value=\"body\").pack(anchor=tk.W)\n",
    "        ttk.Radiobutton(auto_frame, text=\"Center Crop\", variable=self.crop_mode, value=\"center\").pack(anchor=tk.W)\n",
    "        \n",
    "        # Crop size settings\n",
    "        size_frame = ttk.Frame(auto_frame)\n",
    "        size_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(size_frame, text=\"Width:\").grid(row=0, column=0, sticky=tk.W)\n",
    "        self.width_var = tk.StringVar(value=\"300\")\n",
    "        ttk.Entry(size_frame, textvariable=self.width_var, width=8).grid(row=0, column=1, padx=5)\n",
    "        \n",
    "        ttk.Label(size_frame, text=\"Height:\").grid(row=1, column=0, sticky=tk.W)\n",
    "        self.height_var = tk.StringVar(value=\"300\")\n",
    "        ttk.Entry(size_frame, textvariable=self.height_var, width=8).grid(row=1, column=1, padx=5)\n",
    "        \n",
    "        ttk.Button(auto_frame, text=\"Auto Crop All\", command=self.auto_crop_all).pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        # Auto crop info\n",
    "        ttk.Label(auto_frame, text=\"Auto crops resize to specified\", font=('TkDefaultFont', 8)).pack(pady=(5,0))\n",
    "        ttk.Label(auto_frame, text=\"width/height dimensions\", font=('TkDefaultFont', 8)).pack()\n",
    "        \n",
    "        # Output settings\n",
    "        output_frame = ttk.LabelFrame(left_frame, text=\"Output Settings\", padding=10)\n",
    "        output_frame.pack(fill=tk.X, pady=(0, 10))\n",
    "        \n",
    "        # Background color toggle\n",
    "        ttk.Checkbutton(output_frame, text=\"Apply Background Color\", variable=self.apply_bg_color).pack(anchor=tk.W, pady=2)\n",
    "        \n",
    "        # Background color picker\n",
    "        ttk.Button(output_frame, text=\"Select Background Color\", command=self.select_background_color).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        # Color preview\n",
    "        self.bg_color_var = tk.StringVar(value=\"#FFFFFF\")\n",
    "        self.color_preview = tk.Label(output_frame, text=\"      \", background=self.bg_color_var.get(), borderwidth=1, relief=\"solid\")\n",
    "        self.color_preview.pack(anchor=tk.W, pady=2)\n",
    "        \n",
    "        # Display hex value\n",
    "        ttk.Label(output_frame, textvariable=self.bg_color_var).pack(anchor=tk.W)\n",
    "        \n",
    "        # Edge quality settings\n",
    "        edge_frame = ttk.LabelFrame(output_frame, text=\"Edge Quality\", padding=5)\n",
    "        edge_frame.pack(fill=tk.X, pady=5)\n",
    "        \n",
    "        ttk.Label(edge_frame, text=\"Edge Smoothness:\").pack(anchor=tk.W)\n",
    "        edge_scale = ttk.Scale(edge_frame, from_=5.0, to=20.0, variable=self.edge_smoothness, orient=tk.HORIZONTAL)\n",
    "        edge_scale.pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        ttk.Label(edge_frame, text=\"Higher = softer edges\", font=('TkDefaultFont', 8)).pack(anchor=tk.W)\n",
    "        \n",
    "        # Advanced processing toggle\n",
    "        ttk.Checkbutton(edge_frame, text=\"Ultra-Natural Edge Processing\", \n",
    "                       variable=self.use_advanced_processing).pack(anchor=tk.W, pady=5)\n",
    "        ttk.Label(edge_frame, text=\"Uses advanced algorithms for\", font=('TkDefaultFont', 8)).pack(anchor=tk.W)\n",
    "        ttk.Label(edge_frame, text=\"professional-quality results\", font=('TkDefaultFont', 8)).pack(anchor=tk.W)\n",
    "        \n",
    "        ttk.Button(output_frame, text=\"Select Output Folder\", command=self.select_output_folder).pack(fill=tk.X, pady=2)\n",
    "        \n",
    "        self.output_folder = tk.StringVar(value=\"./cropped_images\")\n",
    "        ttk.Label(output_frame, text=\"Output:\").pack(anchor=tk.W)\n",
    "        ttk.Label(output_frame, textvariable=self.output_folder, wraplength=200).pack(anchor=tk.W)\n",
    "        \n",
    "        # Progress bar\n",
    "        self.progress = ttk.Progressbar(left_frame, mode='determinate')\n",
    "        self.progress.pack(fill=tk.X, pady=10)\n",
    "        \n",
    "        # Right panel - Image display\n",
    "        right_frame = ttk.Frame(main_frame)\n",
    "        right_frame.pack(side=tk.RIGHT, fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Canvas for image display\n",
    "        self.canvas = tk.Canvas(right_frame, bg='white', cursor='cross')\n",
    "        self.canvas.pack(fill=tk.BOTH, expand=True)\n",
    "        \n",
    "        # Bind mouse events for manual cropping\n",
    "        self.canvas.bind(\"<Button-1>\", self.start_crop)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_crop)\n",
    "        self.canvas.bind(\"<ButtonRelease-1>\", self.end_crop)\n",
    "        \n",
    "        # Status bar\n",
    "        self.status_label = ttk.Label(self.root, text=\"Ready\", relief=tk.SUNKEN)\n",
    "        self.status_label.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "\n",
    "    def select_background_color(self):\n",
    "        color_code = colorchooser.askcolor(title=\"Choose Background Color\")[1]\n",
    "        if color_code:\n",
    "            self.bg_color_var.set(color_code)\n",
    "            self.color_preview.config(background=color_code)\n",
    "    \n",
    "    def hex_to_bgr(self, hex_color):\n",
    "        h = hex_color.lstrip('#')\n",
    "        return tuple(int(h[i:i+2], 16) for i in (4, 2, 0))  # BGR order\n",
    "\n",
    "    def select_images(self):\n",
    "        try:\n",
    "            files = filedialog.askopenfilenames(\n",
    "                title=\"Select Images\",\n",
    "                filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png *.bmp *.tiff *.gif\")]\n",
    "            )\n",
    "            if files:\n",
    "                self.selected_images = list(files)\n",
    "                self.update_image_count()\n",
    "                self.current_image_index = 0\n",
    "                self.load_current_image()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting images: {str(e)}\")\n",
    "\n",
    "    def select_folder(self):\n",
    "        try:\n",
    "            folder = filedialog.askdirectory(title=\"Select Image Folder\")\n",
    "            if folder:\n",
    "                image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
    "                self.selected_images = []\n",
    "                for file_path in Path(folder).rglob('*'):\n",
    "                    if file_path.suffix.lower() in image_extensions:\n",
    "                        self.selected_images.append(str(file_path))\n",
    "                self.update_image_count()\n",
    "                if self.selected_images:\n",
    "                    self.current_image_index = 0\n",
    "                    self.load_current_image()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting folder: {str(e)}\")\n",
    "\n",
    "    def select_output_folder(self):\n",
    "        try:\n",
    "            folder = filedialog.askdirectory(title=\"Select Output Folder\")\n",
    "            if folder:\n",
    "                self.output_folder.set(folder)\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error selecting output folder: {str(e)}\")\n",
    "\n",
    "    def update_image_count(self):\n",
    "        count = len(self.selected_images)\n",
    "        self.image_count_label.config(text=f\"{count} images selected\")\n",
    "\n",
    "    def load_current_image(self):\n",
    "        if not self.selected_images:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            image_path = self.selected_images[self.current_image_index]\n",
    "            pil_img = Image.open(image_path)\n",
    "            self.current_image = cv2.imread(image_path)\n",
    "            \n",
    "            if self.current_image is None:\n",
    "                messagebox.showerror(\"Error\", f\"Could not load image: {image_path}\")\n",
    "                return\n",
    "                \n",
    "            # Update current image label\n",
    "            filename = os.path.basename(image_path)\n",
    "            self.current_image_label.config(text=f\"{self.current_image_index + 1}/{len(self.selected_images)}: {filename}\")\n",
    "            \n",
    "            # Display image\n",
    "            self.display_image_on_canvas()\n",
    "        except Exception as e:\n",
    "            messagebox.showerror(\"Error\", f\"Error loading image: {str(e)}\")\n",
    "\n",
    "    def display_image_on_canvas(self):\n",
    "        if self.current_image is None:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            if not self.root.winfo_exists():\n",
    "                return\n",
    "                \n",
    "            rgb_image = cv2.cvtColor(self.current_image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            if canvas_width <= 1 or canvas_height <= 1:\n",
    "                self.root.after(100, self.display_image_on_canvas)\n",
    "                return\n",
    "                \n",
    "            img_height, img_width = rgb_image.shape[:2]\n",
    "            \n",
    "            scale_x = canvas_width / img_width\n",
    "            scale_y = canvas_height / img_height\n",
    "            self.scale_factor = min(scale_x, scale_y, 1.0)\n",
    "            \n",
    "            new_width = int(img_width * self.scale_factor)\n",
    "            new_height = int(img_height * self.scale_factor)\n",
    "            \n",
    "            resized_image = cv2.resize(rgb_image, (new_width, new_height))\n",
    "            \n",
    "            pil_image = Image.fromarray(resized_image)\n",
    "            self.display_image = ImageTk.PhotoImage(pil_image, master=self.root)\n",
    "            \n",
    "            self.canvas.delete(\"all\")\n",
    "            self.canvas.create_image(canvas_width//2, canvas_height//2, image=self.display_image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error displaying image: {str(e)}\")\n",
    "            try:\n",
    "                if self.root.winfo_exists():\n",
    "                    messagebox.showerror(\"Error\", f\"Error displaying image: {str(e)}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    def start_crop(self, event):\n",
    "        self.is_cropping = True\n",
    "        self.start_x = event.x\n",
    "        self.start_y = event.y\n",
    "        if self.rect_id:\n",
    "            self.canvas.delete(self.rect_id)\n",
    "\n",
    "    def draw_crop(self, event):\n",
    "        if self.is_cropping:\n",
    "            if self.rect_id:\n",
    "                self.canvas.delete(self.rect_id)\n",
    "            self.rect_id = self.canvas.create_rectangle(\n",
    "                self.start_x, self.start_y, event.x, event.y,\n",
    "                outline='red', width=2\n",
    "            )\n",
    "\n",
    "    def end_crop(self, event):\n",
    "        if self.is_cropping:\n",
    "            self.is_cropping = False\n",
    "            \n",
    "            canvas_width = self.canvas.winfo_width()\n",
    "            canvas_height = self.canvas.winfo_height()\n",
    "            \n",
    "            img_height, img_width = self.current_image.shape[:2]\n",
    "            scaled_width = int(img_width * self.scale_factor)\n",
    "            scaled_height = int(img_height * self.scale_factor)\n",
    "            \n",
    "            img_x = (canvas_width - scaled_width) // 2\n",
    "            img_y = (canvas_height - scaled_height) // 2\n",
    "            \n",
    "            x1 = max(0, int((self.start_x - img_x) / self.scale_factor))\n",
    "            y1 = max(0, int((self.start_y - img_y) / self.scale_factor))\n",
    "            x2 = min(img_width, int((event.x - img_x) / self.scale_factor))\n",
    "            y2 = min(img_height, int((event.y - img_y) / self.scale_factor))\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                self.crop_coords = (x1, y1, x2, y2)\n",
    "            else:\n",
    "                self.crop_coords = None\n",
    "                if self.rect_id:\n",
    "                    self.canvas.delete(self.rect_id)\n",
    "                    self.rect_id = None\n",
    "\n",
    "    def reset_crop(self):\n",
    "        if self.rect_id:\n",
    "            self.canvas.delete(self.rect_id)\n",
    "            self.rect_id = None\n",
    "        self.crop_coords = None\n",
    "\n",
    "    def crop_current_manual(self):\n",
    "        if self.current_image is not None and self.crop_coords:\n",
    "            try:\n",
    "                x1, y1, x2, y2 = self.crop_coords\n",
    "                \n",
    "                img_height, img_width = self.current_image.shape[:2]\n",
    "                x1 = max(0, min(x1, img_width - 1))\n",
    "                y1 = max(0, min(y1, img_height - 1))\n",
    "                x2 = max(0, min(x2, img_width))\n",
    "                y2 = max(0, min(y2, img_height))\n",
    "                \n",
    "                if x2 > x1 and y2 > y1:\n",
    "                    cropped = self.current_image[y1:y2, x1:x2]\n",
    "                    if self.apply_bg_color.get():\n",
    "                        rgb_image = cv2.cvtColor(cropped, cv2.COLOR_BGR2RGB)\n",
    "                        pil_image = Image.fromarray(rgb_image)\n",
    "                        # Ensure RGB format before converting to RGBA\n",
    "                        if pil_image.mode != 'RGB':\n",
    "                            pil_image = pil_image.convert('RGB')\n",
    "                        pil_image_rgba = pil_image.convert(\"RGBA\")\n",
    "                        processed = self.apply_background_replacement(pil_image_rgba)\n",
    "                        cropped = cv2.cvtColor(processed, cv2.COLOR_RGB2BGR)\n",
    "                    self.save_cropped_image_manual(cropped, self.current_image_index)\n",
    "                    messagebox.showinfo(\"Success\", \"Image cropped and saved!\")\n",
    "                else:\n",
    "                    messagebox.showwarning(\"Warning\", \"Invalid crop area selected!\")\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error cropping image: {str(e)}\")\n",
    "        else:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select a crop area first!\")\n",
    "\n",
    "    def prev_image(self):\n",
    "        if self.selected_images and self.current_image_index > 0:\n",
    "            try:\n",
    "                self.current_image_index -= 1\n",
    "                self.load_current_image()\n",
    "                self.reset_crop()\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error loading previous image: {str(e)}\")\n",
    "\n",
    "    def next_image(self):\n",
    "        if self.selected_images and self.current_image_index < len(self.selected_images) - 1:\n",
    "            try:\n",
    "                self.current_image_index += 1\n",
    "                self.load_current_image()\n",
    "                self.reset_crop()\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", f\"Error loading next image: {str(e)}\")\n",
    "\n",
    "    def refine_alpha_mask(self, alpha):\n",
    "        if alpha.ndim == 3:\n",
    "            alpha_2d = alpha.squeeze()\n",
    "        else:\n",
    "            alpha_2d = alpha\n",
    "            \n",
    "        alpha_uint8 = (alpha_2d * 255).astype(np.uint8)\n",
    "        \n",
    "        # Step 1: Advanced edge-preserving smoothing\n",
    "        try:\n",
    "            # Use multiple iterations of bilateral filtering for better edge preservation\n",
    "            alpha_smooth = alpha_uint8.copy()\n",
    "            for _ in range(2):\n",
    "                alpha_smooth = cv2.bilateralFilter(alpha_smooth, 5, 50, 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Bilateral filter failed: {e}\")\n",
    "            alpha_smooth = cv2.GaussianBlur(alpha_uint8, (3, 3), 0)\n",
    "        \n",
    "        # Step 2: Create trimap for better matting\n",
    "        # Define certain foreground, certain background, and uncertain regions\n",
    "        sure_fg = cv2.threshold(alpha_smooth, 240, 255, cv2.THRESH_BINARY)[1]\n",
    "        sure_bg = cv2.threshold(alpha_smooth, 10, 255, cv2.THRESH_BINARY_INV)[1]\n",
    "        uncertain = cv2.subtract(255 - sure_bg, sure_fg)\n",
    "        \n",
    "        # Step 3: Advanced alpha matting using guided filter approach\n",
    "        alpha_float = alpha_smooth.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Create a softer transition in uncertain areas\n",
    "        if np.any(uncertain > 0):\n",
    "            # Apply guided filter-like smoothing in uncertain regions\n",
    "            uncertain_mask = uncertain > 0\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "            \n",
    "            # Create distance-based falloff in uncertain areas\n",
    "            dist_transform = cv2.distanceTransform(sure_fg, cv2.DIST_L2, 5)\n",
    "            smoothness = self.edge_smoothness.get()\n",
    "            \n",
    "            # Normalize distance transform\n",
    "            if dist_transform.max() > 0:\n",
    "                dist_normalized = dist_transform / dist_transform.max()\n",
    "                # Apply smoothness parameter\n",
    "                dist_falloff = np.power(dist_normalized, 1.0 / (smoothness / 10.0))\n",
    "                \n",
    "                # Blend in uncertain regions\n",
    "                alpha_float = np.where(uncertain_mask, \n",
    "                                     dist_falloff * alpha_float + (1 - dist_falloff) * 0.1,\n",
    "                                     alpha_float)\n",
    "        \n",
    "        # Step 4: Multi-scale edge refinement\n",
    "        # Create multiple scales of the alpha mask and blend them\n",
    "        scales = [1, 2, 4]  # Different blur scales\n",
    "        blended_alpha = np.zeros_like(alpha_float)\n",
    "        total_weight = 0\n",
    "        \n",
    "        for scale in scales:\n",
    "            if scale == 1:\n",
    "                scale_alpha = alpha_float\n",
    "                weight = 0.6  # Highest weight for original scale\n",
    "            else:\n",
    "                kernel_size = scale * 2 + 1\n",
    "                scale_alpha = cv2.GaussianBlur(alpha_float, (kernel_size, kernel_size), scale * 0.5)\n",
    "                weight = 0.2  # Lower weight for blurred scales\n",
    "            \n",
    "            blended_alpha += scale_alpha * weight\n",
    "            total_weight += weight\n",
    "        \n",
    "        blended_alpha /= total_weight\n",
    "        \n",
    "        # Step 5: Final edge softening with adaptive blur\n",
    "        # Apply stronger blur to areas with high gradient (edges)\n",
    "        gradient = cv2.Sobel(alpha_uint8, cv2.CV_64F, 1, 1, ksize=3)\n",
    "        gradient_mag = np.sqrt(gradient**2)\n",
    "        gradient_normalized = gradient_mag / (gradient_mag.max() + 1e-8)\n",
    "        \n",
    "        # Create adaptive blur kernel based on gradient\n",
    "        final_alpha = blended_alpha.copy()\n",
    "        for i in range(3):  # Multiple passes for smoother result\n",
    "            adaptive_blur = cv2.GaussianBlur(final_alpha, (5, 5), 1.0)\n",
    "            # Blend more blur in high-gradient areas\n",
    "            blend_factor = gradient_normalized * 0.7\n",
    "            final_alpha = final_alpha * (1 - blend_factor) + adaptive_blur * blend_factor\n",
    "        \n",
    "        return np.clip(final_alpha, 0, 1)\n",
    "\n",
    "    def grabcut_refine_mask(self, image, initial_mask):\n",
    "        \"\"\"Use GrabCut to refine the mask for better edges\"\"\"\n",
    "        try:\n",
    "            # Convert image to BGR for OpenCV\n",
    "            img_bgr = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Create mask for GrabCut (0: background, 1: foreground, 2: probable background, 3: probable foreground)\n",
    "            mask = np.zeros(initial_mask.shape[:2], np.uint8)\n",
    "            \n",
    "            # Set initial mask based on alpha values\n",
    "            mask[initial_mask > 0.8] = 1  # Sure foreground\n",
    "            mask[initial_mask < 0.2] = 0  # Sure background  \n",
    "            mask[(initial_mask >= 0.2) & (initial_mask <= 0.8)] = 3  # Probable foreground\n",
    "            \n",
    "            # Initialize models\n",
    "            bgd_model = np.zeros((1, 65), np.float64)\n",
    "            fgd_model = np.zeros((1, 65), np.float64)\n",
    "            \n",
    "            # Apply GrabCut\n",
    "            cv2.grabCut(img_bgr, mask, None, bgd_model, fgd_model, 3, cv2.GC_INIT_WITH_MASK)\n",
    "            \n",
    "            # Create final mask\n",
    "            refined_mask = np.where((mask == 2) | (mask == 0), 0, 1).astype(np.float32)\n",
    "            \n",
    "            # Smooth the refined mask\n",
    "            refined_mask = cv2.GaussianBlur(refined_mask, (3, 3), 1)\n",
    "            \n",
    "            return refined_mask\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"GrabCut refinement failed: {e}\")\n",
    "            return initial_mask.squeeze() if initial_mask.ndim == 3 else initial_mask\n",
    "\n",
    "    def preprocess_image_for_rembg(self, image):\n",
    "        \"\"\"Preprocess image to improve rembg performance\"\"\"\n",
    "        # Convert PIL to numpy array and ensure it's RGB format\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # Ensure the image is uint8 format\n",
    "        if img_array.dtype != np.uint8:\n",
    "            img_array = img_array.astype(np.uint8)\n",
    "        \n",
    "        # Ensure the image has 3 channels (RGB)\n",
    "        if len(img_array.shape) != 3 or img_array.shape[2] != 3:\n",
    "            return image  # Return original if format is unexpected\n",
    "        \n",
    "        try:\n",
    "            # Apply gentle noise reduction while preserving edges\n",
    "            denoised = cv2.bilateralFilter(img_array, 9, 75, 75)\n",
    "            \n",
    "            # Enhance contrast slightly to help with edge detection\n",
    "            lab = cv2.cvtColor(denoised, cv2.COLOR_RGB2LAB)\n",
    "            l_channel = lab[:, :, 0]\n",
    "            \n",
    "            # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization) to L channel\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "            l_channel = clahe.apply(l_channel)\n",
    "            \n",
    "            lab[:, :, 0] = l_channel\n",
    "            enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2RGB)\n",
    "            \n",
    "            return Image.fromarray(enhanced)\n",
    "        except Exception as e:\n",
    "            print(f\"Preprocessing failed, using original image: {e}\")\n",
    "            return image\n",
    "\n",
    "    def color_spill_suppression(self, image, alpha, background_color):\n",
    "        \"\"\"Remove color spill from original background\"\"\"\n",
    "        img_float = image.astype(np.float32) / 255.0\n",
    "        bg_color = np.array(background_color[:3]) / 255.0  # RGB\n",
    "        \n",
    "        # Detect areas with low alpha (edges) where spill is likely\n",
    "        edge_mask = (alpha < 0.95) & (alpha > 0.05)\n",
    "        \n",
    "        if not np.any(edge_mask):\n",
    "            return image\n",
    "        \n",
    "        # For each channel, reduce the influence of the original background\n",
    "        for c in range(3):\n",
    "            # Calculate the deviation from the background color\n",
    "            deviation = np.abs(img_float[:, :, c] - bg_color[c])\n",
    "            # Apply spill suppression in edge areas\n",
    "            spill_factor = np.clip(deviation * 2, 0, 1)\n",
    "            img_float[edge_mask, c] = img_float[edge_mask, c] * spill_factor[edge_mask] + \\\n",
    "                                     bg_color[c] * (1 - spill_factor[edge_mask])\n",
    "        \n",
    "        return (img_float * 255).astype(np.uint8)\n",
    "\n",
    "    def apply_background_replacement(self, image):\n",
    "        # Preprocess the image for better rembg results\n",
    "        preprocessed_image = self.preprocess_image_for_rembg(image)\n",
    "        \n",
    "        # Remove background using the preprocessed image\n",
    "        removed = remove(preprocessed_image)\n",
    "        fg = np.array(removed).astype(np.float32) / 255.0\n",
    "        alpha_raw = fg[:, :, 3:4]\n",
    "        \n",
    "        # Get refined alpha mask\n",
    "        alpha_refined = self.refine_alpha_mask(alpha_raw)\n",
    "        \n",
    "        # Further refine with GrabCut for ultra-precise edges (if advanced processing enabled)\n",
    "        if self.use_advanced_processing.get():\n",
    "            alpha_refined = self.grabcut_refine_mask(image, alpha_refined)\n",
    "        \n",
    "        # Prepare original foreground (use original image, not preprocessed)\n",
    "        original_fg = np.array(image).astype(np.float32) / 255.0\n",
    "        if original_fg.shape[2] == 4:  # If RGBA, take only RGB\n",
    "            original_fg = original_fg[:, :, :3]\n",
    "        \n",
    "        # Create background with selected color\n",
    "        bg_color_rgb = self.hex_to_bgr(self.bg_color_var.get())\n",
    "        bg_color_rgb = (bg_color_rgb[2], bg_color_rgb[1], bg_color_rgb[0])  # Convert BGR to RGB\n",
    "        \n",
    "        # Step 1: Color spill suppression\n",
    "        original_fg_uint8 = (original_fg * 255).astype(np.uint8)\n",
    "        spill_corrected = self.color_spill_suppression(original_fg_uint8, alpha_refined, bg_color_rgb)\n",
    "        spill_corrected_float = spill_corrected.astype(np.float32) / 255.0\n",
    "        \n",
    "        # Step 2: Edge color harmonization\n",
    "        # Blend edge colors with background color for natural look\n",
    "        alpha_2d = alpha_refined.squeeze() if alpha_refined.ndim == 3 else alpha_refined\n",
    "        edge_mask = (alpha_2d > 0.1) & (alpha_2d < 0.9)\n",
    "        \n",
    "        if np.any(edge_mask):\n",
    "            bg_influence = (1 - alpha_2d[edge_mask]) * 0.3  # 30% background influence on edges\n",
    "            for c in range(3):\n",
    "                spill_corrected_float[edge_mask, c] = \\\n",
    "                    spill_corrected_float[edge_mask, c] * (1 - bg_influence) + \\\n",
    "                    (bg_color_rgb[c] / 255.0) * bg_influence\n",
    "        \n",
    "        # Step 3: Create sophisticated background\n",
    "        bg = np.full((original_fg.shape[0], original_fg.shape[1], 3), \n",
    "                     [bg_color_rgb[0]/255.0, bg_color_rgb[1]/255.0, bg_color_rgb[2]/255.0], \n",
    "                     dtype=np.float32)\n",
    "        \n",
    "        # Add subtle lighting variation to background (makes it look more natural)\n",
    "        h, w = bg.shape[:2]\n",
    "        y, x = np.ogrid[:h, :w]\n",
    "        center_y, center_x = h//2, w//2\n",
    "        \n",
    "        # Create subtle radial gradient for more natural lighting\n",
    "        max_dist = np.sqrt((h/2)**2 + (w/2)**2)\n",
    "        distances = np.sqrt((y - center_y)**2 + (x - center_x)**2)\n",
    "        gradient = 1 - (distances / max_dist) * 0.1  # Very subtle 10% variation\n",
    "        \n",
    "        for c in range(3):\n",
    "            bg[:, :, c] *= gradient\n",
    "        \n",
    "        # Step 4: Advanced alpha blending with multiple passes\n",
    "        alpha_3d = np.expand_dims(alpha_2d, axis=2)\n",
    "        alpha_3d = np.repeat(alpha_3d, 3, axis=2)\n",
    "        \n",
    "        # First pass: Basic compositing\n",
    "        composite = alpha_3d * spill_corrected_float + (1 - alpha_3d) * bg\n",
    "        \n",
    "        # Step 5: Edge refinement with local averaging\n",
    "        # Apply edge smoothing only in transition areas\n",
    "        transition_mask = (alpha_2d > 0.01) & (alpha_2d < 0.99)\n",
    "        if np.any(transition_mask):\n",
    "            # Create a slightly blurred version for edge smoothing\n",
    "            try:\n",
    "                composite_uint8 = (composite * 255).astype(np.uint8)\n",
    "                blurred_composite = cv2.bilateralFilter(composite_uint8, 7, 50, 50).astype(np.float32) / 255.0\n",
    "                \n",
    "                # Blend original and blurred only in transition areas\n",
    "                blend_factor = np.expand_dims((1 - alpha_2d) * 0.5, axis=2)  # Stronger blending for more transparent areas\n",
    "                blend_factor = np.repeat(blend_factor, 3, axis=2)\n",
    "                composite[transition_mask] = composite[transition_mask] * (1 - blend_factor[transition_mask]) + \\\n",
    "                                            blurred_composite[transition_mask] * blend_factor[transition_mask]\n",
    "            except Exception as e:\n",
    "                print(f\"Edge refinement failed: {e}\")\n",
    "        \n",
    "        # Step 6: Final quality enhancement\n",
    "        final_uint8 = (composite * 255).astype(np.uint8)\n",
    "        \n",
    "        # Apply very gentle noise reduction to remove any remaining artifacts\n",
    "        try:\n",
    "            # Use a small kernel to preserve details while smoothing artifacts\n",
    "            final_result = cv2.bilateralFilter(final_uint8, 3, 10, 10)\n",
    "        except Exception as e:\n",
    "            print(f\"Final filtering failed: {e}\")\n",
    "            final_result = final_uint8\n",
    "        \n",
    "        return final_result\n",
    "\n",
    "    def auto_crop_all(self):\n",
    "        if not self.selected_images:\n",
    "            messagebox.showwarning(\"Warning\", \"Please select images first!\")\n",
    "            return\n",
    "            \n",
    "        output_dir = self.output_folder.get()\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        thread = threading.Thread(target=self.process_images_thread)\n",
    "        thread.daemon = True\n",
    "        thread.start()\n",
    "\n",
    "    def process_images_thread(self):\n",
    "        total_images = len(self.selected_images)\n",
    "        self.progress['maximum'] = total_images\n",
    "        \n",
    "        try:\n",
    "            target_width = int(self.width_var.get())\n",
    "            target_height = int(self.height_var.get())\n",
    "        except ValueError:\n",
    "            messagebox.showerror(\"Error\", \"Please enter valid width and height values!\")\n",
    "            return\n",
    "            \n",
    "        success_count = 0\n",
    "        \n",
    "        for i, image_path in enumerate(self.selected_images):\n",
    "            try:\n",
    "                self.root.after(0, lambda: self.status_label.config(text=f\"Processing {i+1}/{total_images}\"))\n",
    "                \n",
    "                img = Image.open(image_path)\n",
    "                # Convert to RGB for consistency, then to RGBA only if needed\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                cropped_img = self.auto_crop_image(img, self.crop_mode.get(), target_width, target_height)\n",
    "                cropped_img = cropped_img.resize((target_width, target_height), Image.LANCZOS)\n",
    "                \n",
    "                if self.apply_bg_color.get():\n",
    "                    # Convert to RGBA for background replacement\n",
    "                    cropped_rgba = cropped_img.convert(\"RGBA\") if cropped_img.mode != 'RGBA' else cropped_img\n",
    "                    final = self.apply_background_replacement(cropped_rgba)\n",
    "                else:\n",
    "                    final = np.array(cropped_img)\n",
    "                \n",
    "                save_path = os.path.join(\n",
    "                    self.output_folder.get(),\n",
    "                    os.path.splitext(os.path.basename(image_path))[0] + \"_auto_crop.png\"\n",
    "                )\n",
    "                Image.fromarray(final).save(save_path)\n",
    "                success_count += 1\n",
    "                \n",
    "                self.root.after(0, lambda: self.progress.config(value=i+1))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {str(e)}\")\n",
    "                continue\n",
    "                \n",
    "        self.root.after(0, lambda: messagebox.showinfo(\"Complete\", f\"Processed {success_count}/{total_images} images successfully!\"))\n",
    "        self.root.after(0, lambda: self.status_label.config(text=\"Ready\"))\n",
    "        self.root.after(0, lambda: self.progress.config(value=0))\n",
    "\n",
    "    def auto_crop_image(self, image, mode, target_width, target_height):\n",
    "        image_cv = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "        height, width = image_cv.shape[:2]\n",
    "        \n",
    "        if mode == \"face\":\n",
    "            gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            \n",
    "            # Log each face detected\n",
    "            for _ in faces:\n",
    "                print(\"1 face detected\")\n",
    "            \n",
    "            if len(faces) > 0:\n",
    "                largest_face = max(faces, key=lambda x: x[2] * x[3])\n",
    "                x, y, w, h = largest_face\n",
    "                \n",
    "                padding = max(w, h) // 2\n",
    "                x1 = max(0, x - padding)\n",
    "                y1 = max(0, y - padding)\n",
    "                x2 = min(width, x + w + padding)\n",
    "                y2 = min(height, y + h + padding)\n",
    "                \n",
    "                cropped = image.crop((x1, y1, x2, y2))\n",
    "                return cropped\n",
    "                \n",
    "        elif mode == \"body\":\n",
    "            gray = cv2.cvtColor(image_cv, cv2.COLOR_BGR2GRAY)\n",
    "            bodies = self.body_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "            \n",
    "            if len(bodies) > 0:\n",
    "                largest_body = max(bodies, key=lambda x: x[2] * x[3])\n",
    "                x, y, w, h = largest_body\n",
    "                \n",
    "                padding = max(w, h) // 4\n",
    "                x1 = max(0, x - padding)\n",
    "                y1 = max(0, y - padding)\n",
    "                x2 = min(width, x + w + padding)\n",
    "                y2 = min(height, y + h + padding)\n",
    "                \n",
    "                cropped = image.crop((x1, y1, x2, y2))\n",
    "                return cropped\n",
    "                \n",
    "        # Default to center crop\n",
    "        aspect_ratio = target_width / target_height\n",
    "        \n",
    "        if width / height > aspect_ratio:\n",
    "            new_width = int(height * aspect_ratio)\n",
    "            x_offset = (width - new_width) // 2\n",
    "            cropped = image.crop((x_offset, 0, x_offset + new_width, height))\n",
    "        else:\n",
    "            new_height = int(width / aspect_ratio)\n",
    "            y_offset = (height - new_height) // 2\n",
    "            cropped = image.crop((0, y_offset, width, y_offset + new_height))\n",
    "            \n",
    "        return cropped\n",
    "\n",
    "    def save_cropped_image_manual(self, cropped_image, index):\n",
    "        try:\n",
    "            output_dir = self.output_folder.get()\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            original_path = self.selected_images[index]\n",
    "            filename = os.path.basename(original_path)\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            \n",
    "            output_path = os.path.join(output_dir, f\"{name}_manual_crop.png\")\n",
    "            success = cv2.imwrite(output_path, cropped_image)\n",
    "            \n",
    "            if not success:\n",
    "                raise Exception(f\"Failed to save image to {output_path}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error saving manually cropped image: {str(e)}\")\n",
    "            raise e\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        root = tk.Tk()\n",
    "        app = ImageCropper(root)\n",
    "        root.mainloop()\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting application: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543eb0b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
